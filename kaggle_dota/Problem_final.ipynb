{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЗАДАЧА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dota 2 — многопользовательская компьютерная игра жанра MOBA. Игроки играют между собой матчи. В каждом матче, как правило, участвует 10 человек. Матчи формируются из живой очереди, с учётом уровня игры всех игроков. Перед началом игры игроки автоматически разделяются на две команды по пять человек. Одна команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire). Цель каждой команды — уничтожить главное здание базы противника, трон.\n",
    "\n",
    "Вам нужно построить модель, которая по данным о первых пяти минутах матча будет предсказывать его исход — то есть определять команду-победителя.\n",
    "\n",
    "Чтобы выполнить это задание, вам необходимо провести ряд исследований, сравнить несколько алгоритмов машинного обучения и проверить эффект от ряда манипуляций с признаками. Также, если вам понравится работать с этими данными, вы можете принять участие в соревновании на Kaggle и сравнить свои навыки с другими участниками курса!\n",
    "\n",
    "К заданию приложены следующие файлы:\n",
    "\n",
    "final-statement.ipynb и final-statement.html — постановка задачи, описание данных, инструкции по выполнению\n",
    "features.zip — архив с обучающей выборкой\n",
    "features_test.zip — архив с тестовой выборкой\n",
    "data.zip — полный архив с сырыми данными и скриптом для извлечения признаков (этот архив понадобится вам только для участия в kaggle; для выполнения данного задания он не нужен)\n",
    "extract_features.py — скрипт, извлекающий признаки из сырых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "\n",
    "import re\n",
    "import scipy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('./features.csv', index_col='match_id', header = 0)\n",
    "features_test = pd.read_csv('./features_test.csv', index_col='match_id', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшение размера выборки (ввиду низкой скорости работы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sample(n=int(len(features)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43939</th>\n",
       "      <td>1444079156</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>1205</td>\n",
       "      <td>868</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72776</th>\n",
       "      <td>1447893839</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>1893</td>\n",
       "      <td>1158</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67687</th>\n",
       "      <td>1447313398</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>1452</td>\n",
       "      <td>1706</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21248</th>\n",
       "      <td>1438308208</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>2130</td>\n",
       "      <td>1335</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>1433665777</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1693</td>\n",
       "      <td>1541</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63129</th>\n",
       "      <td>1447002951</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1522</td>\n",
       "      <td>1242</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>1447771790</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>780</td>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73916</th>\n",
       "      <td>1448080706</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>1316</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60472</th>\n",
       "      <td>1446813060</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>1366</td>\n",
       "      <td>1330</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72149</th>\n",
       "      <td>1447796129</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>941</td>\n",
       "      <td>892</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48615 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "match_id                                                                     \n",
       "43939     1444079156           1      106         4   1205      868      9   \n",
       "72776     1447893839           7       74         5   1893     1158     15   \n",
       "67687     1447313398           1       71         4   1452     1706      8   \n",
       "21248     1438308208           1       46         5   2130     1335     15   \n",
       "8406      1433665777           0        6         4   1693     1541     19   \n",
       "...              ...         ...      ...       ...    ...      ...    ...   \n",
       "63129     1447002951           1       28         4   1522     1242     18   \n",
       "71999     1447771790           7        7         2    780      973      1   \n",
       "73916     1448080706           7       22         4   1200     1316     10   \n",
       "60472     1446813060           1      106         4   1366     1330     20   \n",
       "72149     1447796129           7       28         3    941      892      5   \n",
       "\n",
       "          r1_kills  r1_deaths  r1_items  ...  radiant_ward_sentry_count  \\\n",
       "match_id                                 ...                              \n",
       "43939            0          0         9  ...                          2   \n",
       "72776            0          0         5  ...                          0   \n",
       "67687            2          0         8  ...                          1   \n",
       "21248            0          0         4  ...                          1   \n",
       "8406             1          0        12  ...                          0   \n",
       "...            ...        ...       ...  ...                        ...   \n",
       "63129            0          1        10  ...                          0   \n",
       "71999            1          0         7  ...                          1   \n",
       "73916            1          1        10  ...                          0   \n",
       "60472            0          1         8  ...                          1   \n",
       "72149            1          0        11  ...                          1   \n",
       "\n",
       "          radiant_first_ward_time  dire_bottle_time  dire_courier_time  \\\n",
       "match_id                                                                 \n",
       "43939                       -45.0               NaN              -83.0   \n",
       "72776                       -16.0               NaN              -70.0   \n",
       "67687                       -53.0             221.0                NaN   \n",
       "21248                        -1.0             123.0              -87.0   \n",
       "8406                         55.0               NaN              -86.0   \n",
       "...                           ...               ...                ...   \n",
       "63129                       -37.0             190.0              -87.0   \n",
       "71999                       -28.0               NaN              -87.0   \n",
       "73916                        12.0             244.0              -83.0   \n",
       "60472                       -54.0             178.0              -74.0   \n",
       "72149                         7.0             111.0              -82.0   \n",
       "\n",
       "          dire_flying_courier_time  dire_tpscroll_count  dire_boots_count  \\\n",
       "match_id                                                                    \n",
       "43939                        186.0                    1                 4   \n",
       "72776                          NaN                    1                 3   \n",
       "67687                        259.0                    7                 2   \n",
       "21248                        294.0                    2                 3   \n",
       "8406                           NaN                    6                 4   \n",
       "...                            ...                  ...               ...   \n",
       "63129                        225.0                    2                 4   \n",
       "71999                        183.0                    3                 3   \n",
       "73916                          NaN                    1                 4   \n",
       "60472                          NaN                    2                 3   \n",
       "72149                        181.0                    1                 5   \n",
       "\n",
       "          dire_ward_observer_count  dire_ward_sentry_count  \\\n",
       "match_id                                                     \n",
       "43939                            3                       3   \n",
       "72776                            2                       0   \n",
       "67687                            4                       1   \n",
       "21248                            2                       1   \n",
       "8406                             2                       0   \n",
       "...                            ...                     ...   \n",
       "63129                            2                       1   \n",
       "71999                            3                       0   \n",
       "73916                            2                       0   \n",
       "60472                            2                       1   \n",
       "72149                            3                       2   \n",
       "\n",
       "          dire_first_ward_time  \n",
       "match_id                        \n",
       "43939                    -36.0  \n",
       "72776                    -16.0  \n",
       "67687                    -30.0  \n",
       "21248                     -8.0  \n",
       "8406                       NaN  \n",
       "...                        ...  \n",
       "63129                     -7.0  \n",
       "71999                    -45.0  \n",
       "73916                    205.0  \n",
       "60472                    -37.0  \n",
       "72149                     -2.0  \n",
       "\n",
       "[48615 rows x 102 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features.iloc[:, 0:102]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [X.count()[i] for i in range(len(X.count()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for i in range (len(res)):\n",
    "    if (res[i] < 2*24307):\n",
    "        indexes.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки с пропусками: first_blood_time first_blood_team first_blood_player1 first_blood_player2 radiant_bottle_time radiant_courier_time radiant_flying_courier_time radiant_first_ward_time dire_bottle_time dire_courier_time dire_flying_courier_time dire_first_ward_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_blood_time               244.0\n",
       "first_blood_team                 0.0\n",
       "first_blood_player1              4.0\n",
       "first_blood_player2              9.0\n",
       "radiant_bottle_time            167.0\n",
       "radiant_courier_time           -60.0\n",
       "radiant_flying_courier_time    261.0\n",
       "radiant_first_ward_time        -16.0\n",
       "dire_bottle_time                 NaN\n",
       "dire_courier_time              -70.0\n",
       "dire_flying_courier_time         NaN\n",
       "dire_first_ward_time           -16.0\n",
       "Name: 72776, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.iloc[1][indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерпретация:\n",
    "\n",
    "dire_flying_courier_time - апгрейд курьера команды Dire происходит после пятой минуты.  \n",
    "dire_first_ward_time - первый вард команды Dire устанавливался после пятой минуты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Название столбца с целевой переменной: radiant_win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = features.iloc[:, 103:104].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scorer = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777            4.28s\n",
      "         2           1.3718            3.83s\n",
      "         3           1.3655            2.97s\n",
      "         4           1.3604            2.40s\n",
      "         5           1.3551            1.91s\n",
      "         6           1.3497            1.47s\n",
      "         7           1.3444            1.08s\n",
      "         8           1.3397            0.75s\n",
      "         9           1.3349            0.40s\n",
      "        10           1.3307            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775            2.68s\n",
      "         2           1.3716            2.40s\n",
      "         3           1.3658            2.09s\n",
      "         4           1.3607            1.79s\n",
      "         5           1.3552            1.50s\n",
      "         6           1.3499            1.19s\n",
      "         7           1.3453            0.90s\n",
      "         8           1.3411            0.60s\n",
      "         9           1.3363            0.30s\n",
      "        10           1.3320            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            4.12s\n",
      "         2           1.3724            3.26s\n",
      "         3           1.3661            2.59s\n",
      "         4           1.3612            2.12s\n",
      "         5           1.3563            1.71s\n",
      "         6           1.3510            1.34s\n",
      "         7           1.3460            0.99s\n",
      "         8           1.3416            0.65s\n",
      "         9           1.3371            0.32s\n",
      "        10           1.3329            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772            4.46s\n",
      "         2           1.3712            3.83s\n",
      "         3           1.3657            2.95s\n",
      "         4           1.3603            2.34s\n",
      "         5           1.3548            1.86s\n",
      "         6           1.3494            1.45s\n",
      "         7           1.3442            1.12s\n",
      "         8           1.3394            0.77s\n",
      "         9           1.3349            0.38s\n",
      "        10           1.3303            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774            2.87s\n",
      "         2           1.3716            2.49s\n",
      "         3           1.3654            2.15s\n",
      "         4           1.3594            1.88s\n",
      "         5           1.3542            1.60s\n",
      "         6           1.3491            1.26s\n",
      "         7           1.3436            0.94s\n",
      "         8           1.3389            0.62s\n",
      "         9           1.3348            0.31s\n",
      "        10           1.3307            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777            5.62s\n",
      "         2           1.3718            5.78s\n",
      "         3           1.3655            6.05s\n",
      "         4           1.3604            6.07s\n",
      "         5           1.3551            5.85s\n",
      "         6           1.3497            5.24s\n",
      "         7           1.3444            4.73s\n",
      "         8           1.3397            4.28s\n",
      "         9           1.3349            3.85s\n",
      "        10           1.3307            3.45s\n",
      "        20           1.2951            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775            5.78s\n",
      "         2           1.3716            5.44s\n",
      "         3           1.3658            5.12s\n",
      "         4           1.3607            4.80s\n",
      "         5           1.3552            4.67s\n",
      "         6           1.3499            4.50s\n",
      "         7           1.3453            4.14s\n",
      "         8           1.3411            3.90s\n",
      "         9           1.3363            3.78s\n",
      "        10           1.3320            3.53s\n",
      "        20           1.2978            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            5.80s\n",
      "         2           1.3724            5.47s\n",
      "         3           1.3661            5.11s\n",
      "         4           1.3612            4.79s\n",
      "         5           1.3563            4.49s\n",
      "         6           1.3510            4.19s\n",
      "         7           1.3460            3.89s\n",
      "         8           1.3416            3.59s\n",
      "         9           1.3371            3.29s\n",
      "        10           1.3329            2.99s\n",
      "        20           1.2997            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772            5.62s\n",
      "         2           1.3712            5.35s\n",
      "         3           1.3657            5.04s\n",
      "         4           1.3603            4.75s\n",
      "         5           1.3548            4.45s\n",
      "         6           1.3494            4.17s\n",
      "         7           1.3442            3.87s\n",
      "         8           1.3394            3.57s\n",
      "         9           1.3349            3.27s\n",
      "        10           1.3303            2.98s\n",
      "        20           1.2960            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774            5.78s\n",
      "         2           1.3716            5.46s\n",
      "         3           1.3654            5.12s\n",
      "         4           1.3594            5.09s\n",
      "         5           1.3542            5.12s\n",
      "         6           1.3491            5.06s\n",
      "         7           1.3436            4.68s\n",
      "         8           1.3389            4.28s\n",
      "         9           1.3348            3.89s\n",
      "        10           1.3307            3.53s\n",
      "        20           1.2961            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777           14.50s\n",
      "         2           1.3718           17.36s\n",
      "         3           1.3655           18.11s\n",
      "         4           1.3604           16.19s\n",
      "         5           1.3551           13.99s\n",
      "         6           1.3497           12.72s\n",
      "         7           1.3444           11.44s\n",
      "         8           1.3397           10.47s\n",
      "         9           1.3349            9.60s\n",
      "        10           1.3307            8.90s\n",
      "        20           1.2951            4.19s\n",
      "        30           1.2703            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775           16.21s\n",
      "         2           1.3716           13.79s\n",
      "         3           1.3658           11.52s\n",
      "         4           1.3607           10.21s\n",
      "         5           1.3552            9.32s\n",
      "         6           1.3499            8.62s\n",
      "         7           1.3453            8.04s\n",
      "         8           1.3411            7.53s\n",
      "         9           1.3363            7.07s\n",
      "        10           1.3320            6.65s\n",
      "        20           1.2978            3.27s\n",
      "        30           1.2732            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           16.94s\n",
      "         2           1.3724           13.03s\n",
      "         3           1.3661           11.04s\n",
      "         4           1.3612            9.98s\n",
      "         5           1.3563            9.37s\n",
      "         6           1.3510            8.79s\n",
      "         7           1.3460            8.68s\n",
      "         8           1.3416            8.54s\n",
      "         9           1.3371            8.81s\n",
      "        10           1.3329            8.59s\n",
      "        20           1.2997            4.38s\n",
      "        30           1.2760            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772           13.05s\n",
      "         2           1.3712           13.66s\n",
      "         3           1.3657           12.19s\n",
      "         4           1.3603           10.69s\n",
      "         5           1.3548            9.71s\n",
      "         6           1.3494            8.95s\n",
      "         7           1.3442            8.31s\n",
      "         8           1.3394            7.78s\n",
      "         9           1.3349            7.28s\n",
      "        10           1.3303            6.94s\n",
      "        20           1.2960            3.60s\n",
      "        30           1.2716            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774           11.08s\n",
      "         2           1.3716           10.19s\n",
      "         3           1.3654            9.81s\n",
      "         4           1.3594            9.89s\n",
      "         5           1.3542           10.69s\n",
      "         6           1.3491           11.54s\n",
      "         7           1.3436           11.89s\n",
      "         8           1.3389           11.48s\n",
      "         9           1.3348           10.58s\n",
      "        10           1.3307            9.66s\n",
      "        20           1.2961            3.93s\n",
      "        30           1.2717            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777           12.32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2           1.3718           15.14s\n",
      "         3           1.3655           18.65s\n",
      "         4           1.3604           17.51s\n",
      "         5           1.3551           15.69s\n",
      "         6           1.3497           14.65s\n",
      "         7           1.3444           13.57s\n",
      "         8           1.3397           13.11s\n",
      "         9           1.3349           12.84s\n",
      "        10           1.3307           12.48s\n",
      "        20           1.2951            7.15s\n",
      "        30           1.2703            3.49s\n",
      "        40           1.2519            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775           11.19s\n",
      "         2           1.3716           14.12s\n",
      "         3           1.3658           16.82s\n",
      "         4           1.3607           17.30s\n",
      "         5           1.3552           15.54s\n",
      "         6           1.3499           14.26s\n",
      "         7           1.3453           13.23s\n",
      "         8           1.3411           12.40s\n",
      "         9           1.3363           11.68s\n",
      "        10           1.3320           11.19s\n",
      "        20           1.2978            7.38s\n",
      "        30           1.2732            3.60s\n",
      "        40           1.2552            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           24.96s\n",
      "         2           1.3724           21.39s\n",
      "         3           1.3661           19.14s\n",
      "         4           1.3612           17.01s\n",
      "         5           1.3563           15.47s\n",
      "         6           1.3510           14.34s\n",
      "         7           1.3460           13.49s\n",
      "         8           1.3416           12.64s\n",
      "         9           1.3371           11.92s\n",
      "        10           1.3329           11.27s\n",
      "        20           1.2997            6.71s\n",
      "        30           1.2760            3.42s\n",
      "        40           1.2582            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772           12.05s\n",
      "         2           1.3712           11.89s\n",
      "         3           1.3657           12.03s\n",
      "         4           1.3603           12.08s\n",
      "         5           1.3548           12.49s\n",
      "         6           1.3494           13.02s\n",
      "         7           1.3442           12.63s\n",
      "         8           1.3394           11.94s\n",
      "         9           1.3349           11.33s\n",
      "        10           1.3303           10.88s\n",
      "        20           1.2960            7.11s\n",
      "        30           1.2716            3.47s\n",
      "        40           1.2532            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774           16.81s\n",
      "         2           1.3716           16.66s\n",
      "         3           1.3654           15.84s\n",
      "         4           1.3594           14.26s\n",
      "         5           1.3542           13.14s\n",
      "         6           1.3491           12.35s\n",
      "         7           1.3436           11.67s\n",
      "         8           1.3389           11.06s\n",
      "         9           1.3348           10.85s\n",
      "        10           1.3307           10.77s\n",
      "        20           1.2961            6.93s\n",
      "        30           1.2717            3.43s\n",
      "        40           1.2532            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777           14.85s\n",
      "         2           1.3718           15.29s\n",
      "         3           1.3655           14.60s\n",
      "         4           1.3604           14.11s\n",
      "         5           1.3551           13.70s\n",
      "         6           1.3497           13.34s\n",
      "         7           1.3444           13.07s\n",
      "         8           1.3397           13.39s\n",
      "         9           1.3349           13.06s\n",
      "        10           1.3307           13.20s\n",
      "        20           1.2951            9.92s\n",
      "        30           1.2703            6.48s\n",
      "        40           1.2519            3.29s\n",
      "        50           1.2366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775           15.14s\n",
      "         2           1.3716           14.83s\n",
      "         3           1.3658           14.85s\n",
      "         4           1.3607           15.57s\n",
      "         5           1.3552           15.22s\n",
      "         6           1.3499           14.67s\n",
      "         7           1.3453           14.15s\n",
      "         8           1.3411           14.39s\n",
      "         9           1.3363           14.59s\n",
      "        10           1.3320           14.98s\n",
      "        20           1.2978           11.66s\n",
      "        30           1.2732            7.22s\n",
      "        40           1.2552            3.56s\n",
      "        50           1.2404            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           14.90s\n",
      "         2           1.3724           14.42s\n",
      "         3           1.3661           14.54s\n",
      "         4           1.3612           14.12s\n",
      "         5           1.3563           13.90s\n",
      "         6           1.3510           13.74s\n",
      "         7           1.3460           14.18s\n",
      "         8           1.3416           14.47s\n",
      "         9           1.3371           14.82s\n",
      "        10           1.3329           14.26s\n",
      "        20           1.2997           10.41s\n",
      "        30           1.2760            6.57s\n",
      "        40           1.2582            3.32s\n",
      "        50           1.2427            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772           15.58s\n",
      "         2           1.3712           15.70s\n",
      "         3           1.3657           14.90s\n",
      "         4           1.3603           14.38s\n",
      "         5           1.3548           14.15s\n",
      "         6           1.3494           13.90s\n",
      "         7           1.3442           13.69s\n",
      "         8           1.3394           13.34s\n",
      "         9           1.3349           13.04s\n",
      "        10           1.3303           12.68s\n",
      "        20           1.2960           10.13s\n",
      "        30           1.2716            6.83s\n",
      "        40           1.2532            3.41s\n",
      "        50           1.2376            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774           16.02s\n",
      "         2           1.3716           14.95s\n",
      "         3           1.3654           14.60s\n",
      "         4           1.3594           14.20s\n",
      "         5           1.3542           14.74s\n",
      "         6           1.3491           15.39s\n",
      "         7           1.3436           15.78s\n",
      "         8           1.3389           15.17s\n",
      "         9           1.3348           14.59s\n",
      "        10           1.3307           14.06s\n",
      "        20           1.2961            9.81s\n",
      "        30           1.2717            6.57s\n",
      "        40           1.2532            3.22s\n",
      "        50           1.2385            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777           35.04s\n",
      "         2           1.3718           33.37s\n",
      "         3           1.3655           31.75s\n",
      "         4           1.3604           30.79s\n",
      "         5           1.3551           30.15s\n",
      "         6           1.3497           29.67s\n",
      "         7           1.3444           29.13s\n",
      "         8           1.3397           29.11s\n",
      "         9           1.3349           28.69s\n",
      "        10           1.3307           28.24s\n",
      "        20           1.2951           26.21s\n",
      "        30           1.2703           22.32s\n",
      "        40           1.2519           19.37s\n",
      "        50           1.2366           16.34s\n",
      "        60           1.2241           13.20s\n",
      "        70           1.2134            9.92s\n",
      "        80           1.2042            6.52s\n",
      "        90           1.1953            3.27s\n",
      "       100           1.1873            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775           30.10s\n",
      "         2           1.3716           29.25s\n",
      "         3           1.3658           29.75s\n",
      "         4           1.3607           30.29s\n",
      "         5           1.3552           29.94s\n",
      "         6           1.3499           30.35s\n",
      "         7           1.3453           32.52s\n",
      "         8           1.3411           34.42s\n",
      "         9           1.3363           37.16s\n",
      "        10           1.3320           36.02s\n",
      "        20           1.2978           32.06s\n",
      "        30           1.2732           27.98s\n",
      "        40           1.2552           23.68s\n",
      "        50           1.2404           19.75s\n",
      "        60           1.2277           15.73s\n",
      "        70           1.2167           12.01s\n",
      "        80           1.2071            8.14s\n",
      "        90           1.1989            4.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       100           1.1912            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           36.53s\n",
      "         2           1.3724           41.21s\n",
      "         3           1.3661           41.97s\n",
      "         4           1.3612           39.82s\n",
      "         5           1.3563           37.05s\n",
      "         6           1.3510           35.19s\n",
      "         7           1.3460           34.25s\n",
      "         8           1.3416           33.12s\n",
      "         9           1.3371           32.19s\n",
      "        10           1.3329           31.27s\n",
      "        20           1.2997           30.66s\n",
      "        30           1.2760           26.94s\n",
      "        40           1.2582           22.74s\n",
      "        50           1.2427           19.25s\n",
      "        60           1.2303           15.30s\n",
      "        70           1.2197           11.39s\n",
      "        80           1.2100            7.59s\n",
      "        90           1.2015            3.77s\n",
      "       100           1.1935            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772           29.60s\n",
      "         2           1.3712           29.38s\n",
      "         3           1.3657           30.19s\n",
      "         4           1.3603           29.65s\n",
      "         5           1.3548           29.17s\n",
      "         6           1.3494           29.05s\n",
      "         7           1.3442           29.96s\n",
      "         8           1.3394           31.43s\n",
      "         9           1.3349           32.20s\n",
      "        10           1.3303           31.78s\n",
      "        20           1.2960           26.10s\n",
      "        30           1.2716           22.95s\n",
      "        40           1.2532           19.83s\n",
      "        50           1.2376           17.14s\n",
      "        60           1.2255           13.68s\n",
      "        70           1.2148           10.03s\n",
      "        80           1.2051            6.68s\n",
      "        90           1.1965            3.33s\n",
      "       100           1.1887            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774           41.18s\n",
      "         2           1.3716           46.06s\n",
      "         3           1.3654           44.78s\n",
      "         4           1.3594           40.61s\n",
      "         5           1.3542           38.23s\n",
      "         6           1.3491           36.17s\n",
      "         7           1.3436           34.60s\n",
      "         8           1.3389           33.61s\n",
      "         9           1.3348           32.85s\n",
      "        10           1.3307           31.91s\n",
      "        20           1.2961           27.94s\n",
      "        30           1.2717           25.17s\n",
      "        40           1.2532           21.66s\n",
      "        50           1.2385           18.08s\n",
      "        60           1.2259           14.31s\n",
      "        70           1.2157           10.45s\n",
      "        80           1.2062            6.94s\n",
      "        90           1.1977            3.45s\n",
      "       100           1.1898            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777           58.26s\n",
      "         2           1.3718           50.91s\n",
      "         3           1.3655           48.12s\n",
      "         4           1.3604           49.97s\n",
      "         5           1.3551           50.37s\n",
      "         6           1.3497           48.96s\n",
      "         7           1.3444           49.09s\n",
      "         8           1.3397           51.30s\n",
      "         9           1.3349           54.14s\n",
      "        10           1.3307           56.32s\n",
      "        20           1.2951           47.05s\n",
      "        30           1.2703           44.16s\n",
      "        40           1.2519           40.46s\n",
      "        50           1.2366           36.12s\n",
      "        60           1.2241           32.13s\n",
      "        70           1.2134           27.89s\n",
      "        80           1.2042           24.15s\n",
      "        90           1.1953           20.43s\n",
      "       100           1.1873           16.93s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775           46.19s\n",
      "         2           1.3716           45.14s\n",
      "         3           1.3658           44.69s\n",
      "         4           1.3607           44.27s\n",
      "         5           1.3552           43.96s\n",
      "         6           1.3499           44.35s\n",
      "         7           1.3453           45.35s\n",
      "         8           1.3411           47.32s\n",
      "         9           1.3363           48.93s\n",
      "        10           1.3320           48.83s\n",
      "        20           1.2978           41.74s\n",
      "        30           1.2732           39.06s\n",
      "        40           1.2552           37.54s\n",
      "        50           1.2404           34.27s\n",
      "        60           1.2277           30.70s\n",
      "        70           1.2167           27.27s\n",
      "        80           1.2071           23.68s\n",
      "        90           1.1989           20.46s\n",
      "       100           1.1912           16.95s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           53.04s\n",
      "         2           1.3724           48.69s\n",
      "         3           1.3661           49.15s\n",
      "         4           1.3612           47.49s\n",
      "         5           1.3563           47.73s\n",
      "         6           1.3510           47.23s\n",
      "         7           1.3460           47.44s\n",
      "         8           1.3416           46.59s\n",
      "         9           1.3371           46.03s\n",
      "        10           1.3329           45.77s\n",
      "        20           1.2997           44.61s\n",
      "        30           1.2760           41.64s\n",
      "        40           1.2582           38.51s\n",
      "        50           1.2427           34.40s\n",
      "        60           1.2303           31.24s\n",
      "        70           1.2197           27.22s\n",
      "        80           1.2100           23.82s\n",
      "        90           1.2015           20.61s\n",
      "       100           1.1935           17.13s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772           45.45s\n",
      "         2           1.3712           45.73s\n",
      "         3           1.3657           48.02s\n",
      "         4           1.3603           53.07s\n",
      "         5           1.3548           55.94s\n",
      "         6           1.3494           54.22s\n",
      "         7           1.3442           52.36s\n",
      "         8           1.3394           50.78s\n",
      "         9           1.3349           49.52s\n",
      "        10           1.3303           48.40s\n",
      "        20           1.2960           43.91s\n",
      "        30           1.2716           40.69s\n",
      "        40           1.2532           37.44s\n",
      "        50           1.2376           33.66s\n",
      "        60           1.2255           30.45s\n",
      "        70           1.2148           26.64s\n",
      "        80           1.2051           23.39s\n",
      "        90           1.1965           20.03s\n",
      "       100           1.1887           16.67s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774            1.10m\n",
      "         2           1.3716            1.10m\n",
      "         3           1.3654            1.06m\n",
      "         4           1.3594           58.62s\n",
      "         5           1.3542           55.16s\n",
      "         6           1.3491           52.78s\n",
      "         7           1.3436           50.93s\n",
      "         8           1.3389           49.54s\n",
      "         9           1.3348           48.42s\n",
      "        10           1.3307           47.38s\n",
      "        20           1.2961           40.77s\n",
      "        30           1.2717           38.82s\n",
      "        40           1.2532           35.41s\n",
      "        50           1.2385           32.38s\n",
      "        60           1.2259           29.21s\n",
      "        70           1.2157           26.05s\n",
      "        80           1.2062           23.13s\n",
      "        90           1.1977           19.87s\n",
      "       100           1.1898           16.70s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3777            2.38m\n",
      "         2           1.3718            2.12m\n",
      "         3           1.3655            1.91m\n",
      "         4           1.3604            1.74m\n",
      "         5           1.3551            1.62m\n",
      "         6           1.3497            1.54m\n",
      "         7           1.3444            1.49m\n",
      "         8           1.3397            1.44m\n",
      "         9           1.3349            1.40m\n",
      "        10           1.3307            1.37m\n",
      "        20           1.2951            1.36m\n",
      "        30           1.2703            1.22m\n",
      "        40           1.2519            1.30m\n",
      "        50           1.2366            1.21m\n",
      "        60           1.2241            1.13m\n",
      "        70           1.2134            1.07m\n",
      "        80           1.2042            1.00m\n",
      "        90           1.1953           56.40s\n",
      "       100           1.1873           52.31s\n",
      "       200           1.1275           17.26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3775            1.23m\n",
      "         2           1.3716            1.22m\n",
      "         3           1.3658            1.34m\n",
      "         4           1.3607            1.43m\n",
      "         5           1.3552            1.50m\n",
      "         6           1.3499            1.49m\n",
      "         7           1.3453            1.46m\n",
      "         8           1.3411            1.43m\n",
      "         9           1.3363            1.40m\n",
      "        10           1.3320            1.37m\n",
      "        20           1.2978            1.27m\n",
      "        30           1.2732            1.20m\n",
      "        40           1.2552            1.14m\n",
      "        50           1.2404            1.07m\n",
      "        60           1.2277            1.02m\n",
      "        70           1.2167           57.52s\n",
      "        80           1.2071           56.21s\n",
      "        90           1.1989           54.26s\n",
      "       100           1.1912           52.07s\n",
      "       200           1.1325           17.28s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            1.28m\n",
      "         2           1.3724            1.54m\n",
      "         3           1.3661            1.62m\n",
      "         4           1.3612            1.59m\n",
      "         5           1.3563            1.51m\n",
      "         6           1.3510            1.45m\n",
      "         7           1.3460            1.41m\n",
      "         8           1.3416            1.44m\n",
      "         9           1.3371            1.47m\n",
      "        10           1.3329            1.48m\n",
      "        20           1.2997            1.38m\n",
      "        30           1.2760            1.30m\n",
      "        40           1.2582            1.23m\n",
      "        50           1.2427            1.13m\n",
      "        60           1.2303            1.07m\n",
      "        70           1.2197            1.02m\n",
      "        80           1.2100           56.80s\n",
      "        90           1.2015           53.89s\n",
      "       100           1.1935           50.52s\n",
      "       200           1.1356           16.62s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772            1.27m\n",
      "         2           1.3712            1.25m\n",
      "         3           1.3657            1.26m\n",
      "         4           1.3603            1.40m\n",
      "         5           1.3548            1.48m\n",
      "         6           1.3494            1.50m\n",
      "         7           1.3442            1.45m\n",
      "         8           1.3394            1.42m\n",
      "         9           1.3349            1.39m\n",
      "        10           1.3303            1.36m\n",
      "        20           1.2960            1.21m\n",
      "        30           1.2716            1.21m\n",
      "        40           1.2532            1.12m\n",
      "        50           1.2376            1.08m\n",
      "        60           1.2255            1.02m\n",
      "        70           1.2148           59.19s\n",
      "        80           1.2051           56.42s\n",
      "        90           1.1965           53.07s\n",
      "       100           1.1887           49.32s\n",
      "       200           1.1319           16.21s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3774            1.93m\n",
      "         2           1.3716            1.69m\n",
      "         3           1.3654            1.53m\n",
      "         4           1.3594            1.45m\n",
      "         5           1.3542            1.40m\n",
      "         6           1.3491            1.37m\n",
      "         7           1.3436            1.34m\n",
      "         8           1.3389            1.32m\n",
      "         9           1.3348            1.30m\n",
      "        10           1.3307            1.29m\n",
      "        20           1.2961            1.25m\n",
      "        30           1.2717            1.20m\n",
      "        40           1.2532            1.12m\n",
      "        50           1.2385            1.07m\n",
      "        60           1.2259            1.01m\n",
      "        70           1.2157           58.45s\n",
      "        80           1.2062           55.36s\n",
      "        90           1.1977           51.52s\n",
      "       100           1.1898           48.37s\n",
      "       200           1.1344           16.40s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3779            1.39m\n",
      "         2           1.3722            1.60m\n",
      "         3           1.3664            1.69m\n",
      "         4           1.3612            1.66m\n",
      "         5           1.3563            1.58m\n",
      "         6           1.3515            1.52m\n",
      "         7           1.3465            1.48m\n",
      "         8           1.3419            1.45m\n",
      "         9           1.3375            1.47m\n",
      "        10           1.3338            1.50m\n",
      "        20           1.3003            1.40m\n",
      "        30           1.2771            1.27m\n",
      "        40           1.2596            1.24m\n",
      "        50           1.2455            1.17m\n",
      "        60           1.2341            1.09m\n",
      "        70           1.2243            1.03m\n",
      "        80           1.2157           57.72s\n",
      "        90           1.2084           54.08s\n",
      "       100           1.2010           50.71s\n",
      "       200           1.1500           16.60s\n"
     ]
    }
   ],
   "source": [
    "grid = {'n_estimators': [10, 20, 30, 40, 50, 100, 150, 250]}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=211)\n",
    "clf = GradientBoostingClassifier(verbose=True, random_state=211)\n",
    "gs = GridSearchCV(clf, grid, scoring= roc_auc_scorer, cv=cv)\n",
    "res = gs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 3.524018  ,  6.74609218, 11.34714427, 13.69673181, 16.95702715,\n",
       "        35.33662353, 50.20706058, 83.06706228]),\n",
       " 'std_fit_time': array([0.38439028, 0.53193641, 0.53564724, 0.2417217 , 0.57888267,\n",
       "        2.51352613, 0.70395865, 1.71757404]),\n",
       " 'mean_score_time': array([0.00880194, 0.00820894, 0.014607  , 0.01280313, 0.01321445,\n",
       "        0.0210043 , 0.03320336, 0.03821344]),\n",
       " 'std_score_time': array([0.0011661 , 0.0003928 , 0.00426474, 0.00312237, 0.00193704,\n",
       "        0.00501707, 0.01690163, 0.00597266]),\n",
       " 'param_n_estimators': masked_array(data=[10, 20, 30, 40, 50, 100, 150, 250],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 10},\n",
       "  {'n_estimators': 20},\n",
       "  {'n_estimators': 30},\n",
       "  {'n_estimators': 40},\n",
       "  {'n_estimators': 50},\n",
       "  {'n_estimators': 100},\n",
       "  {'n_estimators': 150},\n",
       "  {'n_estimators': 250}],\n",
       " 'split0_test_score': array([0.6004828 , 0.61561631, 0.621587  , 0.62486551, 0.62382357,\n",
       "        0.63255142, 0.63074948, 0.63027191]),\n",
       " 'split1_test_score': array([0.60736804, 0.62654157, 0.63689481, 0.63836439, 0.64645874,\n",
       "        0.64839986, 0.64865333, 0.64985453]),\n",
       " 'split2_test_score': array([0.61048052, 0.6328358 , 0.63228802, 0.63986319, 0.63962921,\n",
       "        0.6474172 , 0.65058234, 0.65567316]),\n",
       " 'split3_test_score': array([0.60054895, 0.61453576, 0.62449267, 0.62340429, 0.62898287,\n",
       "        0.62911624, 0.63310631, 0.63396886]),\n",
       " 'split4_test_score': array([0.60049188, 0.61693186, 0.63056088, 0.62858463, 0.63105224,\n",
       "        0.6375209 , 0.64284335, 0.6397823 ]),\n",
       " 'mean_test_score': array([0.60387444, 0.62129226, 0.62916468, 0.6310164 , 0.63398933,\n",
       "        0.63900112, 0.64118696, 0.64191016]),\n",
       " 'std_test_score': array([0.00423909, 0.00717897, 0.00549015, 0.00684032, 0.00805392,\n",
       "        0.00775457, 0.00801251, 0.00954541]),\n",
       " 'rank_test_score': array([8, 7, 6, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация для градиентного бустинга с 30 деревьями проводилась 11.34714427 секунд.\n",
    "\n",
    "Получено качество 0.62916468.\n",
    "\n",
    "Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Да, имеет (см. 'mean_test_score').  \n",
    "\n",
    "Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев? Убрать категориальные признаки из обучающей выборки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I итерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-10, -2))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=211)\n",
    "clf = LogisticRegression(penalty = 'l2', random_state=211)\n",
    "gs = GridSearchCV(clf, grid, scoring=roc_auc_scorer, cv=cv)\n",
    "res = gs.fit(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.29291062, 0.21100941, 0.22460461, 0.22980294, 0.24705768,\n",
       "        0.19260497, 0.20000825, 0.37280579]),\n",
       " 'std_fit_time': array([0.05400453, 0.02186276, 0.02534637, 0.02940052, 0.04587625,\n",
       "        0.05728236, 0.01136358, 0.09391039]),\n",
       " 'mean_score_time': array([0.00719624, 0.00959215, 0.00859804, 0.0103982 , 0.00959663,\n",
       "        0.01059628, 0.00778947, 0.00879731]),\n",
       " 'std_score_time': array([0.00097737, 0.00224641, 0.00136034, 0.00326232, 0.00332034,\n",
       "        0.00427123, 0.00411167, 0.00222904]),\n",
       " 'param_C': masked_array(data=[1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-10},\n",
       "  {'C': 1e-09},\n",
       "  {'C': 1e-08},\n",
       "  {'C': 1e-07},\n",
       "  {'C': 1e-06},\n",
       "  {'C': 1e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001}],\n",
       " 'split0_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50075594,\n",
       "        0.62084233, 0.65101119, 0.65912036]),\n",
       " 'split1_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50139216,\n",
       "        0.62331438, 0.64559341, 0.65415032]),\n",
       " 'split2_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50106724,\n",
       "        0.62498938, 0.64679857, 0.64787059]),\n",
       " 'split3_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50074216,\n",
       "        0.61816272, 0.64130241, 0.6503537 ]),\n",
       " 'split4_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50204345,\n",
       "        0.61640125, 0.64248422, 0.65420883]),\n",
       " 'mean_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50120019,\n",
       "        0.62074201, 0.64543796, 0.65314076]),\n",
       " 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.00048431,\n",
       "        0.00316741, 0.00342823, 0.00383296]),\n",
       " 'rank_test_score': array([5, 5, 5, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое качество получилось у логистической регрессии над всеми исходными признаками? \n",
    "0.65314076\n",
    "\n",
    "Как оно соотносится с качеством градиентного бустинга? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом? \n",
    "Логистическая регрессия показала себя лучше, чем градиентный бустинг (как в случае качества, так и времени). Коэффициент ускорения k = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.437146027157997"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.34714427/0.37280579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II итерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filter = features.iloc[:, 0:102].drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filter = X_filter.fillna(0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_f = StandardScaler()\n",
    "scaler_f.fit(X_filter)\n",
    "X_filter_scaled = scaler_f.transform(X_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-10, -2))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=211)\n",
    "clf = LogisticRegression(penalty = 'l2', random_state=211)\n",
    "gs = GridSearchCV(clf, grid, scoring=roc_auc_scorer, cv=cv)\n",
    "res = gs.fit(X_filter_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.20540252, 0.18611193, 0.26701484, 0.18100319, 0.15060959,\n",
       "        0.15000401, 0.18520627, 0.28081203]),\n",
       " 'std_fit_time': array([0.0070603 , 0.00777221, 0.02360078, 0.0291452 , 0.01318321,\n",
       "        0.00836195, 0.0102449 , 0.00831132]),\n",
       " 'mean_score_time': array([0.00699706, 0.00839481, 0.00939898, 0.00759578, 0.00639858,\n",
       "        0.00819454, 0.00779877, 0.00738988]),\n",
       " 'std_score_time': array([0.00141357, 0.00196306, 0.00149805, 0.00338642, 0.00079983,\n",
       "        0.00074666, 0.00116931, 0.00135258]),\n",
       " 'param_C': masked_array(data=[1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-10},\n",
       "  {'C': 1e-09},\n",
       "  {'C': 1e-08},\n",
       "  {'C': 1e-07},\n",
       "  {'C': 1e-06},\n",
       "  {'C': 1e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001}],\n",
       " 'split0_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50086393,\n",
       "        0.62058708, 0.64952876, 0.65725506]),\n",
       " 'split1_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50139216,\n",
       "        0.62305022, 0.64533844, 0.65376275]),\n",
       " 'split2_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50106724,\n",
       "        0.62515796, 0.64570142, 0.64815337]),\n",
       " 'split3_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50074216,\n",
       "        0.61733462, 0.63844528, 0.65111039]),\n",
       " 'split4_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50204345,\n",
       "        0.61523621, 0.64276183, 0.65511372]),\n",
       " 'mean_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50122179,\n",
       "        0.62027322, 0.64435515, 0.65307906]),\n",
       " 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.00046608,\n",
       "        0.0036243 , 0.0036609 , 0.0031681 ]),\n",
       " 'rank_test_score': array([5, 5, 5, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Качество несколько ухудшилось. 0.65307906\n",
    "\n",
    "Коэффициент ускорения k =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.40832677289502"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.34714427/0.28081203"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем вы можете объяснить это изменение? Категориальные признаки подразумевают иную семантику, чем обычные числовые признаки (принадлежность к категории, кто бы мог подумать?) и, следовательно, их прямое взвешивание не может положительно повлиять на качество работы алгоритма. Тем не менее, существенного отрицательного эффекта также не наблюдается.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III итерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = features[['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  25,  26,  27,\n",
       "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 109, 110, 112], dtype=int64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes = np.unique(heroes.to_numpy())\n",
    "heroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько различных идентификаторов героев существует в данной игре? \n",
    "Исходя из данных, не менее 112.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = np.zeros((features.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_united = np.concatenate([X_filter, X_pick], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_u = StandardScaler()\n",
    "scaler_u.fit(X_united)\n",
    "X_united_scaled = scaler_u.transform(X_united)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-10, -2))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=211)\n",
    "clf = LogisticRegression(penalty = 'l2', random_state=211)\n",
    "gs = GridSearchCV(clf, grid, scoring=roc_auc_scorer, cv=cv)\n",
    "res = gs.fit(X_united_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.31040587, 0.30960407, 0.36949439, 0.23820329, 0.33280301,\n",
       "        0.2846034 , 0.30080328, 0.59490261]),\n",
       " 'std_fit_time': array([0.00487689, 0.03251427, 0.03014051, 0.01325739, 0.02831956,\n",
       "        0.03307187, 0.00990351, 0.06824679]),\n",
       " 'mean_score_time': array([0.01019449, 0.00999575, 0.01179805, 0.00799494, 0.01610322,\n",
       "        0.01099706, 0.01139631, 0.01219606]),\n",
       " 'std_score_time': array([0.00213703, 0.00141476, 0.002562  , 0.00063204, 0.00576097,\n",
       "        0.00167602, 0.00224989, 0.00264164]),\n",
       " 'param_C': masked_array(data=[1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-10},\n",
       "  {'C': 1e-09},\n",
       "  {'C': 1e-08},\n",
       "  {'C': 1e-07},\n",
       "  {'C': 1e-06},\n",
       "  {'C': 1e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001}],\n",
       " 'split0_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50086393,\n",
       "        0.63748282, 0.6739839 , 0.68504811]),\n",
       " 'split1_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50160634,\n",
       "        0.63613662, 0.66794971, 0.67918994]),\n",
       " 'split2_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50128068,\n",
       "        0.63780231, 0.6671202 , 0.67673962]),\n",
       " 'split3_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50105814,\n",
       "        0.63145455, 0.66570325, 0.67559849]),\n",
       " 'split4_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.5027963 ,\n",
       "        0.62933997, 0.66649895, 0.67915602]),\n",
       " 'mean_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.50152108,\n",
       "        0.63444326, 0.6682512 , 0.67914643]),\n",
       " 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.00068373,\n",
       "        0.00341659, 0.00295961, 0.00326228]),\n",
       " 'rank_test_score': array([5, 5, 5, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить? 0.67914643. Качество улучшилось и превзошло все предыдущие результаты ввиду корректной конвертации категориального признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_filter = features_test.iloc[:, 0:102].drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)\n",
    "Xt_filter = Xt_filter.fillna(0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_pick = np.zeros((features_test.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(features_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features_test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features_test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_united = np.concatenate([Xt_filter, Xt_pick], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_t = StandardScaler()\n",
    "scaler_t.fit(Xt_united)\n",
    "Xt_united_scaled = scaler_t.transform(Xt_united)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=211, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty = 'l2', random_state=211, C = 0.001)\n",
    "clf.fit(X_united_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(Xt_united_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00814355495445414 0.9895247240588367\n"
     ]
    }
   ],
   "source": [
    "print(str(min(probs)) + \" \" + str(max(probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(probs, index=features_test.index, columns=['radiant_win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('dota_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
